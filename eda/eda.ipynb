{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "import csv\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "matplotlib.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/hduser/workspaces/datakind-workspace/coc.csv\", low_memory=False)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Complaint.Type\"].value_counts().plot(kind=\"barh\", figsize=(10, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Complaint.Date\"].head()\n",
    "\n",
    "# Convert date types \n",
    "dateFormat = \"%m/%d/%Y %H:%M:%S\"\n",
    "df[\"Complaint.Date\"] = pd.to_datetime(df[\"Complaint.Date\"], format=dateFormat)\n",
    "df[\"Resolution.Date\"] = pd.to_datetime(df[\"Resolution.Date\"], format=dateFormat)\n",
    "\n",
    "# add additional columns from the date columns for easier processing\n",
    "df[\"Complaint.Year\"] = df[\"Complaint.Date\"].apply(lambda _ : _.year)\n",
    "df[\"Complaint.Month\"] = df[\"Complaint.Date\"].apply(lambda _ : _.month)\n",
    "df[\"Complaint.Day\"] = df[\"Complaint.Date\"].apply(lambda _ : _.day)\n",
    "df[\"Complaint.Hour\"] = df[\"Complaint.Date\"].apply(lambda _ : _.hour)\n",
    "\n",
    "df[\"Resolution.Year\"] = df[\"Resolution.Date\"].apply(lambda _ : _.year)\n",
    "df[\"Resolution.Month\"] = df[\"Resolution.Date\"].apply(lambda _ : _.month)\n",
    "df[\"Resolution.Day\"] = df[\"Resolution.Date\"].apply(lambda _ : _.day)\n",
    "df[\"Resolution.Hour\"] = df[\"Resolution.Date\"].apply(lambda _ : _.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk.data\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# The TreeBank word tokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "# Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "# common english stop words\n",
    "stop_words = set(stopwords.words('english')).union([stemmer.stem(sw) for sw in stopwords.words('english')])\n",
    "\n",
    "def tokenize(text):\n",
    "    sentences = sent_detector.tokenize(text.lower())\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        # tokenize\n",
    "        toks = tokenizer.tokenize(sentence)\n",
    "        # strip and stem the words\n",
    "        tokens.extend(map(lambda x: stemmer.stem(x.strip()), toks))    \n",
    "    # filter out non-alphanumeric words i.e punctuation and remove stop words    \n",
    "    return filter(lambda x: x.isalnum() and x not in stop_words, tokens)\n",
    "\n",
    "\n",
    "def tokenizeColumn(df, inputColumnName, outputColumnName):\n",
    "    # to deal with python's damned $*@&# unicode issues\n",
    "    df.tempColumn = df[inputColumnName].apply(lambda _: unicode(str(_), \"utf-8\"))\n",
    "    df[outputColumnName] = df.tempColumn.apply(tokenize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smallDf = df.head(1000)\n",
    "tokenizeColumn(smallDf, \"Complaint.Details\", \"Complaint.DetailsTokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smallDf[\"Complaint.DetailsTokenized\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeJaccardIndex(df, idColumn, columnName):\n",
    "    jaccard = {}\n",
    "    for i, row1 in zip(df[idColumn], df[columnName]):\n",
    "        jaccard[i] = {}\n",
    "        for j, row2 in zip(df[idColumn], df[columnName]):            \n",
    "            v1 = set(row1)\n",
    "            v2 = set(row2)\n",
    "            if len(v1) == 0 or len(v2) == 0:\n",
    "                continue\n",
    "            jaccard[i][j] = float(len(v1.intersection(v2))) / len(v1.union(v2))\n",
    "    return jaccard\n",
    "# this takes a long time\n",
    "#jaccard = computeJaccardIndex(smallDf, \"Unnamed: 0\", \"Complaint.DetailsTokenized\")\n",
    "jaccard = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "done = set()\n",
    "writer =  open(\"first100Results.csv\", \"w\")\n",
    "for id1, jacDict in jaccard.iteritems():\n",
    "    for id2, value in jaccard[id1].iteritems():\n",
    "        idSet = \"_\".join(sorted([str(id1), str(id2)]))        \n",
    "        if value > 0.80 and id1 != id2 and idSet not in done:            \n",
    "            done.add(idSet)    \n",
    "            writer.write(\"{},{},{},\\\"{}\\\",\\\"{}\\\"\\n\".format(value, id1, id2,\n",
    "                   smallDf[smallDf[\"Unnamed: 0\"] == id1][\"Complaint.Details\"].values[0].replace(\"\\n\", \"\\\\n\"), \n",
    "                   smallDf[smallDf[\"Unnamed: 0\"] == id2][\"Complaint.Details\"].values[0].replace(\"\\n\", \"\\\\n\")))\n",
    "writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Area\"].value_counts().plot(kind=\"barh\", figsize =(10, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.unique(df[\"Locality\"]).shape\n",
    "print \"nan\" in np.unique(df[\"Locality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.unique(df[\"Street\"]).shape\n",
    "print \"nan\" in np.unique(df[\"Street\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Region\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Zone\"].value_counts().plot(kind=\"bar\", figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Zone\"].value_counts().plot(kind=\"barh\", figsize = (15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Ward\"].value_counts().plot(kind = \"barh\", figsize = (15, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Department\"].value_counts().plot(kind=\"barh\", figsize=(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Complaint.Details\"].value_counts()[:5].plot(kind=\"bar\", figsize = (15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Email\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Complaint.Year\"].value_counts().plot(kind=\"bar\", figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complaintType = \"Dog menace \"\n",
    "year = 2014\n",
    "c = collections.Counter(df[(df[\"Complaint.Type\"] == complaintType) & (df[\"Complaint.Year\"] == year)][\"Complaint.Month\"])\n",
    "sns.barplot(np.array(map(itemgetter(0), c.items())),\n",
    "        np.array(map(itemgetter(1), c.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotComplaintType(df):\n",
    "    for complaintType in df[\"Complaint.Type\"].unique():\n",
    "        for year in df[\"Complaint.Year\"].unique():\n",
    "            slices = df[(df[\"Complaint.Type\"] == complaintType) & (df[\"Complaint.Year\"] == year)]\n",
    "            if len(slices) == 0:\n",
    "                continue\n",
    "            c = collections.Counter(slices[\"Complaint.Month\"])\n",
    "            sns.barplot(np.array(map(itemgetter(0), c.items())),\n",
    "                np.array(map(itemgetter(1), c.items())))\n",
    "            plt.title(\"Complaint Type: {}, Year: {}\".format(complaintType, year))\n",
    "            plt.xlabel(\"Month\")\n",
    "            plt.ylabel(\"Number of Complaints\")\n",
    "            plt.savefig(\"{}_{}.png\".format(year, complaintType.replace(\"/\", \"\")), dpi=200)\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotComplaintType1(df):\n",
    "    for complaintType in df[\"Complaint.Type\"].unique():    \n",
    "        counts = collections.OrderedDict()\n",
    "        for year in sorted(df[\"Complaint.Year\"].unique()):        \n",
    "                slices = df[(df[\"Complaint.Type\"] == complaintType) & (df[\"Complaint.Year\"] == year)]\n",
    "                if len(slices) == 0:\n",
    "                    continue\n",
    "                c = collections.Counter(slices[\"Complaint.Month\"])        \n",
    "                for month in range(1, 13):\n",
    "                    counts[\"{},{}\".format(year, month)] = c.get(month, 0)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        pl = sns.barplot(np.array(map(itemgetter(0), counts.items())),\n",
    "                    np.array(map(itemgetter(1), counts.items())), palette=\"Blues\")\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.setp(labels, rotation=90)\n",
    "        plt.title(\"Complaint Type: {}\".format(complaintType))\n",
    "        plt.xlabel(\"Year / Month\")\n",
    "        plt.ylabel(\"Number of Complaints\")\n",
    "        plt.savefig(\"{} across years.png\".format(complaintType.replace(\"/\", \"\")), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "undup = df.drop_duplicates(['Complaint.Type', 'Area', 'Locality', 'Street', 'Region', 'Zone', 'Ward', 'Complaint.Details', u'Email', u'Mobile', u'Complaint.Month', \"Complaint.Year\", u'Complaint.Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Original: {}, De-duped: {}, Duplicates: {}\".format(df.shape, undup.shape, df.shape[0] - undup.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveDf(df, fileName):\n",
    "    undup.to_csv(fileName, na_rep=\"NA\", index=False, encoding=\"utf-8\", date_format=dateFormat, quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "# saveDf(undup, \"coc_unduplicated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problemCategoryDictionary = df[df[\"Is.Resolved\"] == \"YES\"].drop_duplicates([\"Complaint.Type\",\"Street\", \"Resolution.Year\", \"Resolution.Month\", \"Resolution.Day\"])\n",
    "print problemCategoryDictionary.shape\n",
    "# saveDf(problemCategoryDictionary, \"problemCategoryDictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in sorted(df[\"Complaint.Year\"].unique()):\n",
    "    c = collections.Counter(df[df[\"Complaint.Year\"] == year][\"Is.Resolved\"])\n",
    "    print year, c\n",
    "    print \"Percentage Resolved: {}\".format(float(c[\"YES\"]) / (c[\"YES\"] + c[\"NO\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
